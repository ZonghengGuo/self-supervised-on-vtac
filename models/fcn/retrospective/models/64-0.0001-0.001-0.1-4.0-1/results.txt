D:\code\vtac_unsupervised\models\fcn\retrospective\train.py
{'framework': 'fcn_contrastive', 'differ_loss_weight': 0.001, 'weighted_class': 4.0, 'learning_rate': 0.0001, 'adam_weight_decay': 0.005, 'batch_size': 64, 'max_epoch': 500, 'data_length': 2500}
FCN(
  (convs): Sequential(
    (0): Conv1d(4, 128, kernel_size=(51,), stride=(1,), padding=(25,))
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Conv1d(128, 256, kernel_size=(25,), stride=(1,), padding=(12,))
    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.1, inplace=False)
    (8): Conv1d(256, 128, kernel_size=(13,), stride=(1,), padding=(6,))
    (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.1, inplace=False)
    (12): AdaptiveMaxPool1d(output_size=1)
  )
  (classifier): Sequential(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=64, out_features=1, bias=True)
  )
  (signal_feature): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
  )
)
Num of Parameters: 1.281281M
